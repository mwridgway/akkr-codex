
# The AI-Augmented Productivity Playbook

## 4.1. Document Preamble and Philosophy

This document codifies the architectural principles, technology stack, and development workflows for this project. Its purpose is to ensure consistency, quality, and maximum productivity. We achieve this by leveraging a state-of-the-art stack and a novel development methodology that treats our AI assistant, the Google Gemini CLI, as a core member of the development team. Adherence to these guidelines is mandatory for all contributors.

## 4.2. Core Principles

  - **Architecture: The Modular Monolith.** Our application is a single deployable unit composed of logically isolated modules. Modules communicate only through well-defined public APIs. This provides development simplicity while ensuring long-term maintainability and preparing for future cloud migration.[1]
  - **Technology: The Mandated Stack.** All development will use the officially sanctioned technology stack: Polars for data manipulation, Streamlit for UI, and AutoGen for agentic automation. This ensures consistency and allows us to build collective expertise.[2, 3, 4]
  - **Development: The AI-Augmented Workflow.** The Google Gemini CLI is not just a tool; it is our primary development partner. We use it to orchestrate complex tasks, from scaffolding to code generation and testing. The prompts and scripts in this document represent our codified best practices.[36]

## 4.3. Project Structure Blueprint

All modules and applications must adhere to the following directory structure. This consistency is critical for tooling, automation, and developer onboarding.

```
sales_analyzer/
├──.dockerignore         # Specifies files to ignore in the Docker build
├──.git/                 # Git version control directory
├──.gitignore            # Specifies files for Git to ignore
├── Dockerfile            # Defines the container for the application
├── README.md             # High-level project overview
├── GEMINI.md             # This playbook
├── poetry.lock           # DO NOT EDIT MANUALLY. Generated by Poetry for reproducible builds.
├── pyproject.toml        # Project metadata and dependencies for Poetry
│
├── data/                 # All project data
│   ├── processed/        # Cleaned, transformed data
│   └── raw/              # Immutable, original raw data
│
├── notebooks/            # Jupyter notebooks for exploration and experimentation
│   ├── 01-initial-data-exploration.ipynb
│   └──...
│
├── src/                  # Main application source code
│   └── sales_analyzer/
│       ├── __init__.py
│       ├── agents/       # Modules for AutoGen agents and workflows
│       │   ├── __init__.py
│       │   └── reporting_workflow.py
│       ├── data_processing/ # Modules for data loading and transformation (Polars)
│       │   ├── __init__.py
│       │   └── analysis.py
│       └── visualization/ # Modules related to the Streamlit UI
│           ├── __init__.py
│           └── dashboard_components.py
│
└── tests/                # Unit and integration tests
    ├── __init__.py
    ├── test_data_processing.py
    └──...
```

## 4.4. Getting Started: Environment Setup

Follow these steps precisely to set up your development environment.

1.  **Clone the Repository:**

    ```bash
    git clone <repository_url>
    cd sales_analyzer
    ```

2.  **Install Poetry:** If you do not have Poetry installed, follow the official instructions at [python-poetry.org](https://python-poetry.org/).

3.  **Set Up Python Environment:** This command reads the `poetry.lock` file and installs all project dependencies into a managed virtual environment.

    ```bash
    poetry install
    ```

4.  **Install Google Gemini CLI:** This requires Node.js 20+.[36]

    ```bash
    npm install -g @google/gemini-cli
    ```

5.  **Authenticate Gemini CLI:** This will open a browser window for you to log in with your Google account and authorize the CLI.

    ```bash
    gemini auth
    ```

6.  **Configure Gemini Project:** The first time you run a command, Gemini will prompt you to select a Google Cloud project. Ensure you select the project designated for this application, which must have billing and the "Gemini for Google Cloud API" enabled.[39]

7.  **Activate Virtual Environment:** To run Python scripts or tools like `pytest`, activate the environment managed by Poetry.

    ```bash
    poetry shell
    ```

## 4.5. The Gemini CLI Prompt & Script Library

This library contains tested, reusable prompts and script patterns for common development tasks. Use these as a starting point to ensure consistency and accelerate your work. These can be used interactively in the `gemini` shell or non-interactively via piping.[40]

### Table 3: Gemini CLI Prompt Library for Data App Development

| Task Category | Gemini CLI Prompt / Script Pattern | Description & Usage Notes |
| :--- | :--- | :--- |
| **Scaffolding** | `echo "Scaffold a new module named '$1' in src/sales_analyzer/..." | gemini` | A shell script (`./scripts/new_module.sh <module_name>`) that creates all necessary files and boilerplate for a new application module, including `__init__.py` and a basic test file. |
| **Data Analysis** | `gemini -p "Read the file 'src/sales_analyzer/data_processing/analysis.py'. Inside the 'process_data' function, generate Polars code to..."` | Pattern for generating complex Polars data transformation pipelines from natural language descriptions. Be specific about input/output columns. |
| **UI Generation** | `gemini -p "Generate a Streamlit component in a new function named 'display_revenue_chart'. It should take a Polars DataFrame as input and display..."` | Pattern for creating interactive charts, tables, and input widgets in Streamlit. Specify the exact widget (`st.slider`, `st.multiselect`) and chart type. |
| **Agent Logic** | `gemini -p "Define an AutoGen AssistantAgent named 'code_writer'. Its system message should be: 'You are an expert Python developer...'. It should not have code execution enabled."` | Pattern for scaffolding the definitions of specialized AutoGen agents. Clearly define the agent's persona and capabilities in the system message. |
| **Orchestration** | `gemini -p "Create an AutoGen GroupChat and Manager to orchestrate a conversation between the 'user_proxy' and 'data_analyst' agents. The chat should terminate once..."` | Pattern for defining the interaction workflow between multiple AutoGen agents. Specify termination conditions and speaker transition rules. |
| **Documentation** | `gemini -p "Read the function 'process_data' in 'src/sales_analyzer/data_processing/analysis.py' and generate a comprehensive Google-style docstring for it."` | Automates the creation of high-quality documentation for existing code, improving maintainability. |
| **Testing** | `gemini -p "Generate a pytest unit test for the function 'calculate_revenue' in 'src/sales_analyzer/data_processing/analysis.py'. Create a mock Polars DataFrame for input and assert the output is correct."` | Accelerates the creation of unit tests for data processing and agent logic. Provide clear examples of input and expected output. |

## 4.6. Deployment Guidelines

The application is designed for cloud portability via containerization.

1.  **Build the Docker Image:** From the project root directory, run the following command. This will use the `Dockerfile` to build a portable image of the application.

    ```bash
    docker build -t sales-analyzer-app.
    ```

2.  **Run Locally:** To test the containerized application on your local machine, run:

    ```bash
    docker run -p 8501:8501 sales-analyzer-app
    ```

    The application will be accessible at `http://localhost:8501`.

3.  **Cloud Deployment (High-Level Guide):**

      * **Push Image to a Registry:** Push your built Docker image to a container registry like Google Artifact Registry, AWS Elastic Container Registry (ECR), or Docker Hub.
        ```bash
        # Example for Google Artifact Registry
        docker tag sales-analyzer-app <region>-docker.pkg.dev/<project-id>/<repo-name>/sales-analyzer-app
        docker push <region>-docker.pkg.dev/<project-id>/<repo-name>/sales-analyzer-app
        ```
      * **Deploy to a Serverless Container Platform:** Use a service like Google Cloud Run or AWS App Runner to deploy the container from the registry. These platforms manage scaling, networking, and infrastructure automatically.[9, 42, 43]
      * **Configuration:** Use the platform's built-in mechanisms for managing secrets and environment variables to provide cloud-specific configurations (e.g., database connection strings, API keys) to your container at runtime. This practice aligns with the principle of separating configuration from code and is essential for a secure and flexible cloud deployment.[13]
